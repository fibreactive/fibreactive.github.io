<!DOCTYPE html>
<html prefix="og:http://ogp.me/ns#" lang="en">

  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="Content-Language" content="en">

    <meta name="author" content="Damilola Dolor">
    <meta name="description" content="Building a web scrapper in golang">
    <meta name="keywords" content="damilola,dolor,damilola dolor,blog,developer,personal,software,backend,web developer">
     <meta property="og:description" content="Building a web scrapper in golang">
    <meta name="twitter:description" content="Building a web scrapper in golang">
     <meta itemprop="description" content="Building a web scrapper in golang">
    
      <script src="https://twemoji.maxcdn.com/v/latest/twemoji.min.js" crossorigin="anonymous"></script>
    

    <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Web scraping with go and go-colly"/>
<meta name="twitter:description" content="Building a web scrapper in golang"/>

    <meta property="og:title" content="Web scraping with go and go-colly" />
<meta property="og:description" content="Building a web scrapper in golang" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://0xdod.github.io/posts/web-scraping-with-go/" />
<meta property="article:published_time" content="2020-12-25T20:38:40+01:00" />
<meta property="article:modified_time" content="2020-12-25T20:38:40+01:00" />


    
      <base href="https://0xdod.github.io/posts/web-scraping-with-go/">
    
    <title itemprop="name">
  Web scraping with go and go-colly · damiloladolor
</title>
    <meta property="og:title" content="Web scraping with go and go-colly | damiloladolor" />
    <meta name="twitter:title" content="Web scraping with go and go-colly | damiloladolor" />
    <meta itemprop="name" content="Web scraping with go and go-colly | damiloladolor" />
    <meta name="application-name" content="Web scraping with go and go-colly | damiloladolor" />
    <meta property="og:site_name" content="" />

    
      <base href="https://0xdod.github.io/posts/web-scraping-with-go/">
      <link rel="canonical" href="https://0xdod.github.io/posts/web-scraping-with-go/" itemprop="url" /> 
      <meta name="url" content="https://0xdod.github.io/posts/web-scraping-with-go/" />
      <meta name="twitter:url" content="https://0xdod.github.io/posts/web-scraping-with-go/" /> 
      <meta property="og:url" content="https://0xdod.github.io/posts/web-scraping-with-go/" />
    

    <link href="https://fonts.googleapis.com/css?family=Lato:400,700%7CMerriweather:300,700%7CSource+Code+Pro:400,700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.13.0/css/all.css" integrity="sha384-Bfad6CLCknfcloXFOyFnlgtENryhrpZCe29RTifKEixXQZ38WheV+i/6YWSzkz3V" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.1/normalize.min.css" integrity="sha256-l85OmPOjvil/SOvVt3HnSSjzF1TUMyT9eV0c2BzEGzU=" crossorigin="anonymous" />

    
      
      
      <link rel="stylesheet" href="https://0xdod.github.io/css/coder.min.b3350a7d31456b90f54806f1df520c64865527a58e6a5be10e554ca322896354.css" integrity="sha256-szUKfTFFa5D1SAbx31IMZIZVJ6WOalvhDlVMoyKJY1Q=" crossorigin="anonymous" media="screen" />
    

    

      
        
        
        <link rel="stylesheet" href="https://0xdod.github.io/css/coder-dark.min.c0948b241969586994a1a1f0fb623a7521a3ec99e40accc3c2bba7cd4b7c3c69.css" integrity="sha256-wJSLJBlpWGmUoaHw&#43;2I6dSGj7JnkCszDwrunzUt8PGk=" crossorigin="anonymous" media="screen" />
      

    

    

    <link rel="icon" type="image/png" href="https://0xdod.github.io/images/favicon-32x32.png" sizes="32x32">
    <link rel="icon" type="image/png" href="https://0xdod.github.io/images/favicon-16x16.png" sizes="16x16">
    <meta name="robots" content="index,follow" /> 
    <meta name="googlebot" content="index,follow" />

    <meta name="generator" content="Hugo 0.74.0-DEV" />
  </head>

  
  
  <body class="colorscheme-light"
        onload=" twemoji.parse(document.body); "
  >
    <main class="wrapper">
      <nav class="navigation">
  <section class="container">
    <a class="navigation-title" href="https://0xdod.github.io/">
      damiloladolor
    </a>
     <button class="btn-toggle" id="btn-toggle">
       <i class="fas fa-moon"></i>
    </button>
    
    <input type="checkbox" id="menu-toggle" />
    <label class="menu-button float-right" for="menu-toggle"><i class="fas fa-bars"></i></label>
    <ul class="navigation-list">
      
        
          <li class="navigation-item">
            <a class="navigation-link" href="https://0xdod.github.io/about/">About</a>
          </li>
        
          <li class="navigation-item">
            <a class="navigation-link" href="https://0xdod.github.io/posts/">Blog</a>
          </li>
        
          <li class="navigation-item">
            <a class="navigation-link" href="https://0xdod.github.io/projects/">Projects</a>
          </li>
        
          <li class="navigation-item">
            <a class="navigation-link" href="https://0xdod.github.io/contact/">Contact me</a>
          </li>
        
      
      
    </ul>
    
  </section>
</nav>


      <div class="content">
        
  <section class="container post">
    <article>
      <header>
        <div class="post-title">
          <h1 class="title">Web scraping with go and go-colly</h1>
        </div>
        <div class="post-meta">
          <div class="date">
            <span class="posted-on">
              <i class="fas fa-calendar"></i>
              <time datetime='2020-12-25T20:38:40&#43;01:00'>
                December 25, 2020
              </time>
            </span>
            <span class="reading-time">
              <i class="fas fa-clock"></i>
              5-minute read
            </span>
          </div>
          <div class="categories">
  <i class="fas fa-folder"></i>
    <a href="https://0xdod.github.io/categories/go/">go</a>
      <span class="separator">•</span>
    <a href="https://0xdod.github.io/categories/golang/">golang</a></div>

          <div class="tags">
  <i class="fas fa-tag"></i>
    <a href="https://0xdod.github.io/tags/web-scraping/">web scraping</a>
      <span class="separator">•</span>
    <a href="https://0xdod.github.io/tags/go/">go</a>
      <span class="separator">•</span>
    <a href="https://0xdod.github.io/tags/gocolly/">gocolly</a></div>

        </div>
        <div><a href="https://0xdod.github.io/posts/web-scraping-with-go/#disqus_thread"></a></div>
      </header>

      <div>
        
          <img src='https://0xdod.github.io/images/posts/golang.png' alt="Featured image"/>
        
        <p>I have been flirting with go for a few weeks now and I built a simple forum-like website using <a href="https://github.com/gin-gonic/gin">gin</a> which is a popular web framework for golang. After building the application, I was satisfied with how much I was able to learn about the language so I decided to do another little project with it. While I was browsing the web mindlessly(like most of us do), I stumbled upon a comment that talked about web scrapping in python then an idea popped in my mind, why not scrape the frontpage of a popular online forum then use the data to populate my own database. Now, scraping a website is not illegal, but it&rsquo;s good you should know what you can and cannot scrape from a website. Many websites have a <strong>robots.txt</strong> file which gives such information. While there are tons of web scrapping tutorials on the web mostly in python, I felt there weren&rsquo;t enough of them in go so I decided to write one.  I did my research and found out an elegant golang framework for scraping websites called <a href="https://go-colly.org">colly</a>, and with this tool I was able to scrape the frontpage of a popular Nigerian forum called <a href="https://nairaland.com/">Nairaland</a>.</p>
<p>The Go language has a ton of hype around it as it&rsquo;s relatively new, the syntax is relatively easy to pick up as compared to other statically typed languages, it is very fast and natively supports concurrency which makes it a language of choice for many in building cloud services and network applications. We can leverage this speed to scrape websites in a fast and easy way.</p>
<h5 id="web-scraping">Web Scraping</h5>
<p><a href="https://en.wikipedia.org/wiki/Web_scraping">Web scraping</a> is a form of data extraction that basically extracts data from websites. A web scraper is usually a bot that uses the HTTP protocol to access websites, extract HTML elements from them and use the data for various purposes.
I&rsquo;ll be sharing with you how you can scrape a website with minimal effort in go, let&rsquo;s go 🚀</p>
<p>First, you will need to have go installed on your system and know the basics of the language before you can proceed.
We&rsquo;ll start by creating a folder to house our project, open your terminal and create a folder.</p>
<div class="highlight"><pre style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">mkdir scraping-with-go
<span style="color:#fff;font-weight:bold">cd</span> scraping-with-go 
</code></pre></div><p>Then initialize a go module, using the go toolchain.</p>
<div class="highlight"><pre style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">go mod init github.com/&lt;USERNAME&gt;/&lt;PROJECTNAME&gt;/
</code></pre></div><p>Replace the username and project name with appropriate values, by now we should have two files in our folder called go.mod and go.sum, these will track our dependencies.
Next we go get colly with the following command.</p>
<div class="highlight"><pre style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">go get -v github.com/gocolly/colly
</code></pre></div><p>Then we can get our hands dirty. Create a new main.go file and fire up your favorite text editor or IDE.</p>
<div class="highlight"><pre style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-go" data-lang="go"><span style="color:#fff;font-weight:bold">package</span> main

<span style="color:#007f7f">// Post is a struct representing a single post in nairaland
</span><span style="color:#007f7f"></span><span style="color:#fff;font-weight:bold">type</span> Post <span style="color:#fff;font-weight:bold">struct</span> {
	Author <span style="color:#fff;font-weight:bold">string</span>
	URL    <span style="color:#fff;font-weight:bold">string</span>
	Body   <span style="color:#fff;font-weight:bold">string</span>
	Title  <span style="color:#fff;font-weight:bold">string</span>
}
</code></pre></div><p>The above is the data structure we will be storing a single post in, it will contain necessary information about a single post. This was all I needed to populate my database, I was not interested in getting the comments since we all know how toxic the comments section of  forums can be :).</p>
<div class="highlight"><pre style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-go" data-lang="go"><span style="color:#fff;font-weight:bold">func</span> main() {
	URL := <span style="color:#0ff;font-weight:bold">&#34;https://nairaland.com/&#34;</span>
	log.Println(<span style="color:#0ff;font-weight:bold">&#34;Visiting&#34;</span>, URL)

	c := colly.NewCollector(colly.CacheDir(<span style="color:#0ff;font-weight:bold">&#34;./nl_cache&#34;</span>))
	postCollector := c.Clone()
	posts := <span style="color:#fff;font-weight:bold">make</span>([]Post, <span style="color:#ff0;font-weight:bold">0</span>, <span style="color:#ff0;font-weight:bold">100</span>)
}
</code></pre></div><p>We need to call the NewCollector function to create our web scrapper, then using CSS selectors, we can identify specific elements to extract data from. The main idea is that we target specific nodes, extract data, build our data structure and dump it in a json file. After inspecting the nairaland HTML structure (which I think is quite messy), I was able to target the specific nodes I wanted.</p>
<div class="highlight"><pre style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-go" data-lang="go">...
c.OnHTML(<span style="color:#0ff;font-weight:bold">&#34;td.featured.w a[href]&#34;</span>, <span style="color:#fff;font-weight:bold">func</span>(e *colly.HTMLElement) {
		postCollector.Visit(e.Attr(<span style="color:#0ff;font-weight:bold">&#34;href&#34;</span>))
	})
</code></pre></div><p>The OnHTML method registers a callback function to be called every time the scrapper comes across an html node with the selector we passed in. The above code visits every link of frontpage news.</p>
<div class="highlight"><pre style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-go" data-lang="go">...
postCollector.OnHTML(<span style="color:#0ff;font-weight:bold">`table[summary=&#34;posts&#34;] tbody`</span>, <span style="color:#fff;font-weight:bold">func</span>(e *colly.HTMLElement) {
		log.Println(<span style="color:#0ff;font-weight:bold">&#34;Post found&#34;</span>, e.Request.URL)
		<span style="color:#fff;font-weight:bold">var</span> p Post
		p.Title = e.ChildText(<span style="color:#0ff;font-weight:bold">&#34;tr:first-child td.bold.l.pu a[href]:nth-child(4)&#34;</span>)
		p.Author = e.ChildText(<span style="color:#0ff;font-weight:bold">`tr:first-child td.bold.l.pu:first-child a[class=&#34;user&#34;]`</span>)
		p.Body = e.ChildText(<span style="color:#0ff;font-weight:bold">&#34;tr:nth-child(2) td.l.w.pd:first-child div.narrow&#34;</span>)
		p.URL = e.Request.URL.String()
		posts = <span style="color:#fff;font-weight:bold">append</span>(posts, p)
	})

	c.OnRequest(<span style="color:#fff;font-weight:bold">func</span>(r *colly.Request) {
		log.Println(<span style="color:#0ff;font-weight:bold">&#34;Visiting: &#34;</span>, r.URL)
	})
	c.OnResponse(<span style="color:#fff;font-weight:bold">func</span>(r *colly.Response) {
		log.Println(<span style="color:#0ff;font-weight:bold">&#34;Visited: &#34;</span>, r.Request.URL)
	})
	c.Visit(URL)
</code></pre></div><p>What is happening here is that when we visit each link to a frontpage news, we extract the title, url, body and author name using CSS selectors to identify where they are located, we then build up our post struct with this data and append it to our slice. The OnRequest and OnResponse functions registers a callback each to be called when our scrapper makes a request and receives a response respectively. With this data at our disposal, we can then serialize it into json to be dumped on disk. There are other storage backends you can use if you want to do something advanced, checkout the <a href="https://go-colly.org/docs">docs</a>. We then make a call to c.Visit to visit our target website.</p>
<div class="highlight"><pre style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-go" data-lang="go">...
<span style="color:#fff;font-weight:bold">var</span> buf bytes.Buffer
	enc := json.NewEncoder(&amp;buf)
	enc.SetIndent(<span style="color:#0ff;font-weight:bold">&#34; &#34;</span>, <span style="color:#0ff;font-weight:bold">&#34;\t&#34;</span>)
	err := enc.Encode(posts)
	<span style="color:#fff;font-weight:bold">if</span> err != <span style="color:#fff;font-weight:bold">nil</span> {
		log.Println(<span style="color:#0ff;font-weight:bold">&#34;failed to serialize response: &#34;</span>, err)
		<span style="color:#fff;font-weight:bold">return</span>
	}
	err = ioutil.WriteFile(<span style="color:#0ff;font-weight:bold">&#34;posts.json&#34;</span>, buf.Bytes(), <span style="color:#ff0;font-weight:bold">0644</span>)
	<span style="color:#fff;font-weight:bold">if</span> err != <span style="color:#fff;font-weight:bold">nil</span> {
		log.Fatal(err)
	}
	fmt.Println(buf.String())
</code></pre></div><p>We use the standard library&rsquo;s json package to serialize json then write it to a file on disk, and voila we have written our first scrapping tool in golang, easy right?. Armed with this tool, you can conquer all the web, but remember to check the <em>robots.txt</em> file which tells you what data you can scrape and how to handle the data. You can read more about the robots file <a href="http://www.robotstxt.org">here</a>, and remeber to visit the <a href="http://go-colly.org">docs</a> to learn more there&rsquo;s a ton of great examples you can follow along there. Cheers  ✌️</p>
<p>Thank you for reading</p>

      </div>


      <footer>
        


        <div id="disqus_thread"></div>
<script>
    

    
    var disqus_config = function () {
    this.page.url = "https://0xdod.github.io/posts/web-scraping-with-go/";  
    this.page.identifier = "2cc1f9cfe1a3c49ea9eabef7207aba2b"; 
    };
    
    (function() { 
    var d = document, s = d.createElement('script');
    s.src = 'https://portfolio-lrpi5ggzul.disqus.com/embed.js';
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
        
        
      </footer>
    </article>

    
  </section>

      </div>

      
  <footer class="footer">
    <section class="container">
      
        <p>Damilola Dolor</p>
      
      
        ©
        
        2020
         Damilola Dolor 
      
      
         · 
        Powered by <a href="https://gohugo.io/">Hugo</a> & <a href="https://github.com/luizdepra/hugo-coder/">Coder</a>.
      
      
    </section>
  </footer>

    </main>

    

    

    <script>
(function(f, a, t, h, o, m){
	a[h]=a[h]||function(){
		(a[h].q=a[h].q||[]).push(arguments)
	};
	o=f.createElement('script'),
	m=f.getElementsByTagName('script')[0];
	o.async=1; o.src=t; o.id='fathom-script';
	m.parentNode.insertBefore(o,m)
})(document, window, '//analytics.example.com/tracker.js', 'fathom');
fathom('set', 'siteId', 'ABCDE');
fathom('trackPageview');
</script>

    <script>
            const btn = document.querySelector("#btn-toggle");
            const currentTheme = localStorage.getItem("theme");
            
            if (currentTheme == "dark") {
                document.body.classList.add("colorscheme-dark")
                btn.firstElementChild.classList.add("fa-sun")
            }
            btn.addEventListener('click', function(){
                document.body.classList.toggle("colorscheme-dark");
                let theme = 'light';
                if (document.body.classList.contains('colorscheme-dark')) { 
                    theme = 'dark'
                }
                document.body.setAttribute('style', "transition: all .8s;")
                localStorage.setItem("theme",theme)
                btn.firstElementChild.classList.toggle("fa-sun")       
            })
      </script> 
      <script id="dsq-count-scr" src="//portfolio-lrpi5ggzul.disqus.com/count.js" async></script>
  </body>

</html>
